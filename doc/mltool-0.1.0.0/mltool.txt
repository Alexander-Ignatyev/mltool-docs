-- Hoogle documentation, generated by Haddock
-- See Hoogle, http://www.haskell.org/hoogle/


-- | Machine Learning Toolbox
--   
--   Please see README.md
@package mltool
@version 0.1.0.0


-- | Common type definitions used in all modules.
module MachineLearning.Types

-- | Scalar Type (Double)
type R = R

-- | Vector Types (of Doubles)
type Vector = Vector R

-- | Matrix Types (of Doubles)
type Matrix = Matrix R


-- | Regression Model type class.
module MachineLearning.Model
class Model a

-- | Hypothesis function, a.k.a. score function (for lassifition problem)
--   Takes X (m x n) and theta (n x 1), returns y (m x 1).
hypothesis :: Model a => a -> Matrix -> Vector -> Vector

-- | Cost function J(Theta), a.k.a. loss function. It takes regularizarion
--   parameter lambda, matrix X (m x n), vector y (m x 1) and vector theta
--   (n x 1).
cost :: Model a => a -> R -> Matrix -> Vector -> Vector -> R

-- | Gradient function. It takes regularizarion parameter lambda, X (m x
--   n), y (m x 1) and theta (n x 1). Returns vector of gradients (n x 1).
gradient :: Model a => a -> R -> Matrix -> Vector -> Vector -> Vector


module MachineLearning.LeastSquaresModel
data LeastSquaresModel
LeastSquares :: LeastSquaresModel
instance MachineLearning.Model.Model MachineLearning.LeastSquaresModel.LeastSquaresModel


module MachineLearning.LogisticModel
data LogisticModel
Logistic :: LogisticModel

-- | Calculates sigmoid
sigmoid :: Floating a => a -> a

-- | Calculates derivatives of sigmoid
sigmoidGradient :: Floating a => a -> a
instance MachineLearning.Model.Model MachineLearning.LogisticModel.LogisticModel


module MachineLearning.Optimization.GradientDescent

-- | Gradient Descent method implementation. See
--   <a>MachineLearning.Regression</a> for usage details.
gradientDescent :: Model a => R -> a -> R -> Int -> R -> Matrix -> Vector -> Vector -> (Vector, Matrix)


-- | Optimization module.
module MachineLearning.Optimization
data MinimizeMethod

-- | Gradient descent, takes alpha. Requires feature normalization.
GradientDescent :: R -> MinimizeMethod

-- | Fletcher-Reeves conjugate gradient algorithm, takes size of first
--   trial step (0.1 is fine) and tol (0.1 is fine).
ConjugateGradientFR :: R -> R -> MinimizeMethod

-- | Polak-Ribiere conjugate gradient algorithm. takes size of first trial
--   step (0.1 is fine) and tol (0.1 is fine).
ConjugateGradientPR :: R -> R -> MinimizeMethod

-- | Broyden-Fletcher-Goldfarb-Shanno (BFGS) algorithm, takes size of first
--   trial step (0.1 is fine) and tol (0.1 is fine).
BFGS2 :: R -> R -> MinimizeMethod

-- | Returns solution vector (theta) and optimization path. Optimization
--   path's row format: [iter number, cost function value, theta values...]
minimize :: Model a => MinimizeMethod -> a -> R -> Int -> R -> Matrix -> Vector -> Vector -> (Vector, Matrix)

-- | Gradient checking function. Approximates the derivates of the Model's
--   cost function and calculates derivatives using the Model's gradient
--   functions. Returns norn_2 between 2 derivatives. Takes model, lambda,
--   X, y, theta and epsilon (used to approximate derivatives, 1e-4 is a
--   good value).
checkGradient :: Model a => a -> R -> Matrix -> Vector -> Vector -> R -> R


module MachineLearning.Regression
class Model a

-- | Hypothesis function, a.k.a. score function (for lassifition problem)
--   Takes X (m x n) and theta (n x 1), returns y (m x 1).
hypothesis :: Model a => a -> Matrix -> Vector -> Vector

-- | Cost function J(Theta), a.k.a. loss function. It takes regularizarion
--   parameter lambda, matrix X (m x n), vector y (m x 1) and vector theta
--   (n x 1).
cost :: Model a => a -> R -> Matrix -> Vector -> Vector -> R

-- | Gradient function. It takes regularizarion parameter lambda, X (m x
--   n), y (m x 1) and theta (n x 1). Returns vector of gradients (n x 1).
gradient :: Model a => a -> R -> Matrix -> Vector -> Vector -> Vector
data LeastSquaresModel
LeastSquares :: LeastSquaresModel
data MinimizeMethod

-- | Gradient descent, takes alpha. Requires feature normalization.
GradientDescent :: R -> MinimizeMethod

-- | Fletcher-Reeves conjugate gradient algorithm, takes size of first
--   trial step (0.1 is fine) and tol (0.1 is fine).
ConjugateGradientFR :: R -> R -> MinimizeMethod

-- | Polak-Ribiere conjugate gradient algorithm. takes size of first trial
--   step (0.1 is fine) and tol (0.1 is fine).
ConjugateGradientPR :: R -> R -> MinimizeMethod

-- | Broyden-Fletcher-Goldfarb-Shanno (BFGS) algorithm, takes size of first
--   trial step (0.1 is fine) and tol (0.1 is fine).
BFGS2 :: R -> R -> MinimizeMethod

-- | Returns solution vector (theta) and optimization path. Optimization
--   path's row format: [iter number, cost function value, theta values...]
minimize :: Model a => MinimizeMethod -> a -> R -> Int -> R -> Matrix -> Vector -> Vector -> (Vector, Matrix)

-- | Normal equation using inverse, does not require feature normalization
--   It takes X and y, returns theta.
normalEquation :: Matrix -> Vector -> Vector

-- | Normal equation using pseudo inverse, requires feature normalization
--   It takes X and y, returns theta.
normalEquation_p :: Matrix -> Vector -> Vector


-- | Binary and Multiclass Classification.
module MachineLearning.Classification
data MinimizeMethod

-- | Gradient descent, takes alpha. Requires feature normalization.
GradientDescent :: R -> MinimizeMethod

-- | Fletcher-Reeves conjugate gradient algorithm, takes size of first
--   trial step (0.1 is fine) and tol (0.1 is fine).
ConjugateGradientFR :: R -> R -> MinimizeMethod

-- | Polak-Ribiere conjugate gradient algorithm. takes size of first trial
--   step (0.1 is fine) and tol (0.1 is fine).
ConjugateGradientPR :: R -> R -> MinimizeMethod

-- | Broyden-Fletcher-Goldfarb-Shanno (BFGS) algorithm, takes size of first
--   trial step (0.1 is fine) and tol (0.1 is fine).
BFGS2 :: R -> R -> MinimizeMethod

-- | Binary Classification prediction function. Takes a matrix of features
--   X and a vector theta. Returns predicted class.
predictBinary :: Matrix -> Vector -> Vector

-- | Multiclass Classification prediction function. Takes a matrix of
--   features X and a list of vectors theta, returns predicted class number
--   assuming that class numbers start at 0.
predictMulti :: Matrix -> [Vector] -> Vector

-- | Calculates accuracy of Classification predictions. Takes vector
--   expected y and vector predicted y. Returns number from 0 to 1, the
--   closer to 1 the better accuracy. Suitable for both Classification
--   Types: Binary and Multiclass.
calcAccuracy :: Vector -> Vector -> R

-- | Process outputs for Multiclass Classification. Takes number of labels
--   and output vector y. Returns list of vectors of binary outputs
--   (One-vs-All Classification). It is supposed that labels are integerets
--   start at 0.
processOutputMulti :: Int -> Vector -> [Vector]

-- | Learns Binary Classification.
learnBinary :: MinimizeMethod -> R -> Int -> R -> Matrix -> Vector -> Vector -> (Vector, Matrix)

-- | Learns Multiclass Classification
learnMulti :: MinimizeMethod -> R -> Int -> R -> Matrix -> [Vector] -> [Vector] -> ([Vector], [Matrix])


-- | Randon generation uitility functions.
module MachineLearning.Random

-- | Samples <tt>n</tt> (given as a second parameter) values from
--   <tt>list</tt> (given as a third parameter).
sample :: RandomGen g => g -> Int -> Vector a -> (Vector a, g)

-- | Samples <tt>n</tt> (given as a second parameter) values from
--   <tt>list</tt> (given as a third parameter) inside RandomMonad.
sampleM :: RandomGen g => Int -> Vector a -> Rand g (Vector a)

-- | Returns a list of random values distributed in a closed interval
--   <tt>range</tt>
getRandomRListM :: (RandomGen g, Random a) => Int -> (a, a) -> Rand g [a]

-- | Returns a vector of random values distributed in a closed interval
--   <tt>range</tt>
getRandomRVectorM :: RandomGen g => Int -> (R, R) -> Rand g Vector

-- | Returns a matrix of random values distributed in a closed interval
--   <tt>range</tt>
getRandomRMatrixM :: RandomGen g => Int -> Int -> (R, R) -> Rand g Matrix


-- | Cluster Analysis a.k.a. Clustering - grouping data into coherent
--   subsets.
module MachineLearning.Clustering

-- | Cluster type (list of samples associtaed with the cluster).
type Cluster = Vector Vector

-- | Clusters data using K-Means Algorithm inside Random Monad. Runs
--   K-Means algorithm <tt>N</tt> times, returns the clustering with
--   smaller cost.
kmeans :: RandomGen g => Int -> Matrix -> Int -> Rand g (Vector Cluster)

-- | Run K-Means algorithm once inside Random Monad.
kmeansIterM :: RandomGen g => Vector Vector -> Int -> Int -> Rand g (Vector Cluster, [R])


-- | Learn function with progress bar for terminal.
module MachineLearning.TerminalProgress

-- | Learn the given function displaying progress bar in terminal. It takes
--   function, initial theta and number of iterations to call the function.
--   It returns theta and optimization path (see
--   <a>MachineLearning.Regression</a> for details).
learnWithProgressBar :: (Vector -> (Vector, Matrix)) -> Vector -> Int -> IO (Vector, Matrix)

-- | Learn the given function displaying progress bar in terminal. It takes
--   function, list of outputs and list of initial thetas and number of
--   iterations to call the function. It returns list of thetas and list of
--   optimization paths (see <a>MachineLearning.Regression</a> for
--   details).
learnMultiWithProgressBar :: (Vector -> Vector -> (Vector, Matrix)) -> [Vector] -> [Vector] -> Int -> IO ([Vector], [Matrix])


module MachineLearning

-- | Add biad dimension to the future matrix
addBiasDimension :: Matrix -> Matrix

-- | Remove biad dimension
removeBiasDimension :: Matrix -> Matrix

-- | Caclulates mean and stddev values of every feature. Takes feature
--   matrix X, returns pair of vectors of means and stddevs.
meanStddev :: Matrix Double -> (Matrix Double, Matrix Double)
featureNormalization :: Fractional a => (a, a) -> a -> a

-- | Maps the features into all polynomial terms of X up to the degree-th
--   power
mapFeatures :: Int -> Matrix -> Matrix

-- | Splits data matrix to features matrix X and vector of outputs y
splitToXY :: Element t => Matrix t -> (Matrix t, Vector t)


-- | Simple Neural Networks.
module MachineLearning.NeuralNetwork
class Model a

-- | Hypothesis function, a.k.a. score function (for lassifition problem)
--   Takes X (m x n) and theta (n x 1), returns y (m x 1).
hypothesis :: Model a => a -> Matrix -> Vector -> Vector

-- | Cost function J(Theta), a.k.a. loss function. It takes regularizarion
--   parameter lambda, matrix X (m x n), vector y (m x 1) and vector theta
--   (n x 1).
cost :: Model a => a -> R -> Matrix -> Vector -> Vector -> R

-- | Gradient function. It takes regularizarion parameter lambda, X (m x
--   n), y (m x 1) and theta (n x 1). Returns vector of gradients (n x 1).
gradient :: Model a => a -> R -> Matrix -> Vector -> Vector -> Vector

-- | Neural Network Model. Takes neural network topology as a constructor
--   argument.
newtype NeuralNetworkModel
NeuralNetwork :: Topology -> NeuralNetworkModel

-- | Neural network topology has at least 2 elements: numver of input and
--   number of outputs. And sizes of hidden layers between 2 elements. Bias
--   input must not be included.
data Topology

-- | Creates toplogy. Takes number of inputs, number of outputs and list of
--   hidden layers.
makeTopology :: Int -> Int -> [Int] -> Topology

-- | Create and initialize weights vector with random values for given
--   neural network topology. Takes a seed to initialize generator of
--   random numbers as a first parameter.
initializeTheta :: Int -> Topology -> Vector

-- | Create and initialize weights vector with random values for given
--   neural network topology inside IO Monad.
initializeThetaIO :: Topology -> IO Vector

-- | Create and initialize weights vector with random values for given
--   neural network topology inside RandomMonad.
initializeThetaM :: RandomGen g => Topology -> Rand g Vector

-- | Calculates accuracy of Classification predictions. Takes vector
--   expected y and vector predicted y. Returns number from 0 to 1, the
--   closer to 1 the better accuracy. Suitable for both Classification
--   Types: Binary and Multiclass.
calcAccuracy :: Vector -> Vector -> R

-- | Flatten list of matrices into vector.
flatten :: [Matrix] -> Vector

-- | Unflatten vector into list of matrices for given neural network
--   topology.
unflatten :: Topology -> Vector -> [Matrix]

-- | Returns dimensions of weight matrices for given neural network
--   topology
getThetaSizes :: Topology -> [(Int, Int)]

-- | Return sum of dimensions of weight matrices for given neural network
--   topology.
getThetaTotalSize :: Topology -> Int

-- | Create and initialize list of weights matrices with random values for
--   given neural network topology.
initializeThetaListM :: RandomGen g => Topology -> Rand g [Matrix]
instance MachineLearning.Model.Model MachineLearning.NeuralNetwork.NeuralNetworkModel


-- | Principal Component Analysis (PCA) - dimensionality reduction
--   algorithm. It is mostly used to speed up supervising learning
--   (Regression, Classification, etc) and visualization of data.
module MachineLearning.PCA

-- | Gets dimensionality reduction function, retained variance (0..1) and
--   reduced X for given matrix X and number of dimensions to retain.
getDimReducer :: Matrix -> Int -> (Matrix -> Matrix, R, Matrix)

-- | Gets dimensionality reduction function, retained number of dimensions
--   and reduced X for given matrix X and variance to retain (0..1].
getDimReducer_rv :: Matrix -> R -> (Matrix -> Matrix, Int, Matrix)
